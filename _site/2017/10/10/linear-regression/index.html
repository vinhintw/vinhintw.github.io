<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Linear Regression &middot; Vinh Ng
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
  <!-- <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->

  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-BF3TPWNBEM"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-BF3TPWNBEM');
  </script>

  <!-- toogle button -->
  <script>
  function myFunction() {
      var x = document.getElementById("myDIV");
      if (x.style.display === "none") {
          x.style.display = "block";
      } else {
          x.style.display = "none";
      }
  }
  </script>
  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>A personal website of <a href="https://vinhintw.github.io/about" target="">Vinh Ng</a>, containing technical blog on technology.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/about/">About</a>
        
      
    
      
    
      
        
      
    
      
        
      
    
    <span class="sidebar-nav-item">Currently v1.0.0</span>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2023. All rights reserved.
    </p>
  </div>
</div>

 
    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Vinh Ng</a>
            <small>blog</small>
          </h3>
        </div>
      </div>

      <link rel="stylesheet" href="/public/css/blog-index.css">

<nav>
	<div class='blog-wrapper'>
		<div class='blog-index'>
			<strong><u>Machine learning</u></strong></br>
				<li><a href=''>6. Gradient Descent</a></li>
				<li><a href=''>5. K Nearest Neighbors</a></li>
				<li><a href=''>4. Linear Regression</a></li>
				<li><a href=''>3. AI for flappy bird game (Neural Network, Genetic Algorithm)</a></li>
				<li><a href=''>2. Image Compression using K-Means</a></li>
				<li><a href=''>1. K-Means Clustering</a></li>
			<strong><u>Data Structure and Algorithm</u></strong></br>
				<li><a href=''>1. Linked List</a></li>
				<li><a href=''>2. Stack, Queue</a>
			<strong><u>Other</u></strong></br>
				<li><a href=''>4. Mapping MySQL to MongoDB</a></li>
				<li><a href=''>3. University MySQL DB</a></li>
				<li><a href=''>2. Planetary Rover Game (C#, Winform)</a></li>
				<li><a href=''>1. Music Player (Python)</a></li>
			<strong><u>Project</u></strong></br>
		</div>
	</div>
</nav>

      <div class="container content">
        <div class="post">
  <h1 style="font-size: 130%;" class="post-title">Linear Regression</h1>
  <span class="post-date" style="float:none;">10 Oct 2017</span>
  
  <div class="tag">Linear Algebra</div>
<div class="tag">Projection</div>
<div class="tag">Least Square</div>
<div class="tag">Supervised Learning</div>
<p><strong>Content:</strong>
<!-- MarkdownTOC depth=3 --></p>

<ul>
  <li><a href="#1-introduction">1. Introduction</a></li>
  <li><a href="#2-least-square-approximation-and-cost-function">2. Least Square Approximation and Cost Function</a></li>
  <li><a href="#3-solving-optimization-problem">3. Solving Optimization Problem</a>
    <ul>
      <li><a href="#31-by-geometry">3.1. By Geometry</a></li>
      <li><a href="#32-by-algebra">3.2. By Algebra</a></li>
      <li><a href="#33-by-calculus">3.3. By Calculus</a></li>
    </ul>
  </li>
  <li><a href="#4-discussion">4. Discussion</a>
    <ul>
      <li><a href="#41-fitting-a-parabola">4.1. Fitting a parabola</a></li>
    </ul>
  </li>
  <li><a href="#5-coding-with-python">5. Coding with Python</a></li>
  <li><a href="#6-further-topics-to-study">6. Further topics to study</a></li>
  <li><a href="#7-reference">7. Reference</a></li>
</ul>

<!-- /MarkdownTOC -->
<p><a name="1-introduction"></a></p>
<h2 id="1-introduction">1. Introduction</h2>
<p>Suppose we have a dataset containing information of \(m\) houses which were sold in a specific area, the data contains area in meter square \((a_1)\), number of windows \((a_2)\), number of rooms \((a_3)\), and lastly, price \((b)\). We understand that \(\textbf{a}=[a_1,a_2,a_3]\) has an influence on the price of the house. Our gold is to predict the price of house providing that we have information about area, number of windows, number of rooms. This prediction is valuable because we can use predicted price to estimate the price of house we want to sell so that it will not be too high or too low regardless of the prices of all houses in the location or we can also use predicted price to determine whether the house that someone is selling is too expensive in comparision with the prices of other houses.</p>

<p>Linear Regression is a model to solve prediction problem. \(b\) will be expressed as a linear function of \(a_1, a_2, a_3\):
\begin{equation} \tag{1}\label{eq:1}
\mathbf{b}=f(\textbf{a})=x_0+x_1a_1+x_2a_2+x_3a_3
\end{equation}
The problem is we cannot always find a linear relationship that fit all the data in the dataset. Our goal is to solve the linear regression problem: Find the coefficients \(\textbf{x}=[x_0, x_1, x_2, x_3]\) so that \(b\approx f(\textbf{a})\) for as much data as possible.
<a name="2-least-square-approximation-and-cost-function"></a></p>
<h2 id="2-least-square-approximation-and-cost-function">2. Least Square Approximation and Cost Function</h2>
<p>Let \(\textbf{b}=[b_1, b_2,...,b_m]\) be the vector containing the value of \(m\) trainning data in dataset that we want to predict, in our example, they are \(m\) house prices.</p>

<p>Let \(A=[1, \mathbf{a_1} , \mathbf{a_2}, \mathbf{a_3},..., \mathbf{a_n}]\) be the matrix containing all feature data, \(\mathbf{a_1}, \mathbf{a_2},..., \mathbf{a_n}\) are column vectors containing all data of \(n\) features. In our example, \(n=3\), \(\mathbf{a_1}\) is column vector containing area in square meter of \(m\) houses, \(\mathbf{a_2}\) is column vector containing number of windows of \(m\) houses.</p>

<p>Letâ€™s take a quick look at this example again:</p>
<div class="imgcap">
<img style="display: inline-block; width: 45%; float:left" src="/public/post-assets/LinearRegression/example.png" width="500" align="center" />
</div>
<p><br />
\(A=[1, \mathbf{a_1} , \mathbf{a_2}, \mathbf{a_3}] = \begin{bmatrix}
 1 &amp; 120 &amp; 4 &amp; 3 \\ 
 1 &amp; 200 &amp; 6 &amp; 4 \\ 
 1 &amp; 80 &amp; 2 &amp; 2 \\ 
 1 &amp; 60 &amp; 1 &amp; 1 \\ 
 1 &amp; 3000 &amp; 9 &amp; 6 
\end{bmatrix}, 
b = \begin{bmatrix}
10000 \\
12200 \\
70000 \\
50000 \\
19000 
\end{bmatrix}\)</p>
<div style="clear:left;"></div>
<p>The linear equation \eqref{eq:1} become
\begin{equation} \tag{2}\label{eq:2}
A\mathbf{x}=\mathbf{b}
\end{equation}  <br />
It is often happens that \(A\mathbf{x}=\mathbf{b}\) has no solution. The usual reason is there are too many equations. The matrix \(A\) has more rows than columns (\(m&gt;n\), more data the the number of features). In this case, \(b\) is a vector outside of column space of A. We cannot always get the error \(\mathbf{e}=\mathbf{b}-A\mathbf{x}\) down to zero. When \(\mathbf{e}\) is zero, \(\mathbf{x}\) is an exact solution to \(A\mathbf{x}=\mathbf{b}\). <strong>When the length of</strong> \(\mathbf{e}\) <strong>is as small as posible,</strong> \(\hat{\mathbf{x}}\) is a <strong>least square solution.</strong></p>

<p>With the definition of least square solution above, the format of the cost/loss function is:
\begin{equation} \tag{3}\label{eq:3}
L(\mathbf{x})=||e||^2=||A\mathbf{x}-\mathbf{b}||^2_2
\end{equation}</p>

<p>The notation \(||\mathbf{x}||_ 2\) is <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)">Euclidean norm</a>.If \(\mathbf{x}=(x_1, x_2,...,x_n)\) is a vector on a \(n\)-dimensional space \(R^n\) then \(||x||_ 2:=\sqrt{x_1^2+x_2^2+...+x_n^2}\). Therefore, the loss function is defined by the sum of square error:
\begin{equation} \tag{4}\label{eq:4}
L(\mathbf{x}) = \sum_{i=1}^{m}(\mathbf{w_i}\mathbf{x}-\mathbf{b_i})^2
\end{equation}</p>

<p>\(\mathbf{w_i}\) is row vector i of matrix \(A\). In our example, each \(\mathbf{w_i}\) is a row vector containing information of a house.
<a name="3-solving-optimization-problem"></a></p>
<h2 id="3-solving-optimization-problem">3. Solving Optimization Problem</h2>
<p>The optimal \(\hat{\mathbf{x}}\) when \(A\mathbf{x}=\mathbf{b}\) has no solution is the solution of \(A^TA\hat{\mathbf{x}}=A^Tb\). The following part will be the proof of that statement.</p>

<p>Before we move on the proof, letâ€™s reduce the dimension of data so that itâ€™s possible to visualize. The new problem we will solve is: Find the closest line to the points: \((0,6),(1,0),(2,0)\) or predict \(y-coordinate\) by \(x-coordinate\).</p>

<p>No straight line \(b=C+Dx\) goes through those three points. We are asking for two numbers C and D that satisfy three equations. Here are the equations at \(x=0,1,2\) to match the given values \(b=6,0,0\):
\[C + D.0 = 6\]
\[C + D.1 = 0\]
\[C + D.2 = 0\]
This 3x2 system has no solution because \(\mathbf{b}=[6,0,0]\) is not in the column space of matrix with 2 basis: \([1,1,1]\) and \([0,1,2]\). In other words, \(A\mathbf{x}=\mathbf{b}\) has no solution.
\(A =\) 
\(\begin{bmatrix}
1 &amp; 0\\
1 &amp; 1\\
1 &amp; 2
\end{bmatrix}\)
, \(\mathbf{x} =\) 
\(\begin{bmatrix}
C\\
D
\end{bmatrix}\)
, 
\(\mathbf{b} =\) 
\(\begin{bmatrix}
6\\
0\\
0
\end{bmatrix}\)</p>
<div class="imgcap">
	<img style="display: inline-block; width: 80%;" src="/public/post-assets/LinearRegression/fig1.png" width="500" align="center" />
	<div class="thecap">Image taken from <a href="http://math.mit.edu/~gs/linearalgebra/">Introduction to Linear Algebra book</a> <br /></div>
</div>

<p><a name="31-by-geometry"></a></p>
<h3 id="31-by-geometry">3.1. By Geometry</h3>
<p>We are looking for a linear combination of basis of matrix \(A\), this linear combination produce a vector in the column space of \(A\) in order to minimize the length of vector \(\mathbf{e}\), \(||e||^2=||A\mathbf{x}-\mathbf{b}||^2_2\) as in equation \eqref{eq:3}. This vector \(\mathbf{e}\) is a vector from \(\mathbf{b}\) (Iâ€™m refering a vector as a point) to a point in column space of \(A\) . The smallest distance is \(\textbf{e}\) as in figure 4.6b above: \(\mathbf{e}=\mathbf{b}-\mathbf{p}\) with \(\mathbf{p}\) be the <strong>projection</strong> of vector \(\textbf{b}\) onto column space \(C(A)\).</p>

<p>To recap, we have proved that loss function \(L(\mathbf{x})\) is minimized when \(A\mathbf{x}\) create a projection of \(\textbf{b}\) onto column space. 
The formular for projection of a vector onto a subspace is:
\begin{equation} \tag{5}\label{eq:5}
\mathbf{p}=A(A^TA)^{-1}A^T\mathbf{b}
\end{equation}
The solution \(\hat{\mathbf{x}}\) is:</p>

<p>\begin{equation} \tag{8}\label{eq:8}
\hat{\mathbf{x}} = (A^TA)^{-1}A^T\mathbf{b}
\end{equation}</p>

<p>Proof: \(\mathbf{b}-A\mathbf{\hat{x}}\) is the error vector that is perpendicular to column space \(C(A)\). It means \(\mathbf{b}-A\mathbf{\hat{x}}\) is perpendicular to every vectors lied on \(C(A)\). Therefore, their dot product equal to 0: \(\mathbf{a_i}^T(\mathbf{b}-A\mathbf{\hat{x}})=0\) for \(i\) in range \((1,m)\). This leads to \(A^T(\mathbf{b}-A\mathbf{\hat{x}})=0\).
<a name="32-by-algebra"></a></p>
<h3 id="32-by-algebra">3.2. By Algebra</h3>
<p>Every vector \(\mathbf{b}\) outside of column space of A can be splited into two parts. The part in column space \(\mathbf{p}\) and the perpendicular part \(\mathbf{e}\) in the nullspace of \(A^T\) (left null space of \(A\)). The reason is that column space of A (all vectors which are linear combination of column vector of matrix \(A\)) is perpendicular to left null space of \(A\) (all vectors \(\mathbf{x}\) that \(A^T\mathbf{x}=0\)). The two subspace mentioned above fill out the whole space of \(A\).</p>

<p>Refer to figure 4.6b, apply the law for right triangle, it stills true if the triangle lied in high dimensional space: 
\begin{equation} \tag{6}\label{eq:6}
||A\mathbf{x}-\mathbf{b}||^2 = ||A\mathbf{x}-\mathbf{p}||^2 + ||\mathbf{e}||^2
\end{equation}
In equation \eqref{eq:6}, \(\mathbf{e}\) is a fixed vector: the error vector of projection of \(\mathbf{b}\) onto column space of \(A\). \(A\mathbf{x}-\mathbf{p}\) is a vector on column space and \(||A\mathbf{x}-\mathbf{b}||^2\) is the least square error needs to be minimized.</p>

<p>\begin{equation} \tag{7}\label{eq:7}
||A\mathbf{x}-\mathbf{b}||^2 = ||A\mathbf{x}-\mathbf{p}||^2 + ||\mathbf{e}||^2 \geq ||\mathbf{e}||^2
\end{equation}
Since \(\mathbf{e}\) is a fixed vector, \(||\mathbf{e}||^2\) is a constant.  Least square error is minimized when \(||A\mathbf{x}-\mathbf{p}||^2=0\), which means the solution \(\hat{\mathbf{x}}\) is:
\begin{equation} \tag{9}\label{eq:9}
\hat{\mathbf{x}}=A^{-1}\mathbf{p}=A^{-1}A(A^TA)^{-1}A^T\mathbf{b}=(A^TA)^{-1}A^T\mathbf{b}
\end{equation}</p>

<p><a name="33-by-calculus"></a></p>
<h3 id="33-by-calculus">3.3. By Calculus</h3>
<p>Rewrite the term we are trying to minimized:
\begin{equation}
E = ||A\mathbf{x}-\mathbf{b}||^2 = (C+D.0-6)^2+(C+D.1)^2+(C+D.2)^2 
\end{equation}
Take partial derivative of E with respect to C and D individually:
\begin{equation}
\partial E / \partial C = 2(C+D.0-6) + 2(C+D.1) + 2(C+D.2) = 0
\end{equation}
\begin{equation}
\partial E / \partial D = 2(C+D.0-6)(0) + 2(C+D.1)(1) + 2(C+D.2)(2) = 0
\end{equation}
The above system gives:
\(\begin{bmatrix}
3 &amp; 3 \\
3 &amp; 5
\end{bmatrix}
\begin{bmatrix}
C \\
D
\end{bmatrix}=
\begin{bmatrix}
6 \\
0
\end{bmatrix}\)
This is identical with \(A^TA\hat{\mathbf{x}}=A^T\mathbf{b}\)</p>

<p>In a more general case, where \(A\) is a \(m\times n\) matrix. Letâ€™s recall the equation \eqref{eq:4} of loss function:
\begin{equation} \tag{4}
L(\mathbf{x}) = \sum_{i=1}^{m}(\mathbf{w_i}\mathbf{x}-\mathbf{b_i})^2
\end{equation}</p>

<p>In order to minimize \(L(\mathbf{x})\), we solve \(\frac{\partial L}{\partial x}=0\) for each \(x\) being element of vector \(\mathbf{x}\).</p>

<p>Using chain rule, the following is derivative of \(L\) with respect to \(x_1\), the first element of \(\mathbf{x}\):</p>

<p>\begin{equation} \tag{10}\label{eq:10}
\frac{\partial L}{\partial x_1} = \sum_{i=1}^{m}2( \mathbf{w_i}\mathbf{x}-\mathbf{b_i})\mathbf{w_i}[0]
\end{equation}</p>

<p>\(\mathbf{w_i}[0]\) is the first element of \(\mathbf{w_i}\). Notice that \(\mathbf{w_i}[0]\) for \(i\) in range \((1,m)\) is the first column of matrix \(A\), also the first row of \(A^T\). Hence, we could rewrite equation \eqref{eq:10} in matrix form:</p>

<p>\begin{equation} \tag{11}\label{eq:11}
\frac{\partial L}{\partial x_1} = 2A^T \lbrack 0 \rbrack (A\mathbf{x}-b)
\end{equation}</p>

<p>In equation \eqref{eq:11}, \(A^T[0]\) is first row of matrix \(A^T\). Keep going with the derivative of \(L\) with respect to every element of \(\mathbf{x}\):</p>

<p>\begin{equation} \tag{12}\label{eq:12}
\frac{\partial L}{\partial \mathbf{x}} = 2A^T(A\mathbf{x}-\mathbf{b})
\end{equation}</p>

<p>In order to minimize \(L(\mathbf{x})\), the derivative in every direction is set to 0, which is \(A^T(A\mathbf{x}-\mathbf{b})=0\) which leads to the solution \(\hat{\mathbf{x}} = (A^TA)^{-1}A^T\mathbf{b}\). This is the same result as in equation \eqref{eq:8} and \eqref{eq:9}. Every approach leads to the same answer.</p>

<p><strong>Note</strong>: the matrix \((A^TA)^{-1}A^T\) is also call <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">pseudo-inverse matrix</a> of \(A\). The notation is \(A^\dagger\) (A dagger), \(A^\dagger=(A^TA)^{-1}A^T\).</p>

<p>Conclusion, if \(A\) is not invertiable, the solution \(\hat{\mathbf{x}}=A^\dagger\mathbf{b}\).
<a name="4-discussion"></a></p>
<h2 id="4-discussion">4. Discussion</h2>
<p>In the case of more than one feature, \(n&gt;1\), column space of \(A\) become more complex (more dimension). In our example, there are 3 data points \((m=3)\), \(m\) is the dimension of the vector space that column space \(C(A)\) and \(\mathbf{b}\) lied in, more data means itâ€™s less likely for \(\mathbf{b}\) to be lied on \(C(A)\). In this case, the solution is the projection of \(\mathbf{b}\) into \(C(A)\). Projection of a vector onto a high dimensional subspace is a vector.</p>

<p><a name="41-fitting-a-parabola"></a></p>
<h3 id="41-fitting-a-parabola">4.1. Fitting a parabola</h3>
<p>Instead of looking for coefficients \(\hat{\mathbf{x}}=[C,D]\) of the line \(b=C+Dt\), we will look for \(\hat{\mathbf{x}}=[C,D,E]\) to fit the parabola \(b=C+Dx+Ex^2\). It means the column space have one more vector: \(A=
\begin{bmatrix}
1 &amp; x_1 &amp; x_1^2 \\
\vdots &amp; \vdots &amp; \vdots \\
1 &amp; x_m &amp; x_m^2
\end{bmatrix}\)
<a name="5-coding-with-python"></a></p>
<h2 id="5-coding-with-python">5. Coding with Python</h2>
<p>Fit a straight line:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># create random data 
</span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">19</span><span class="p">,</span><span class="mi">23</span><span class="p">,</span><span class="mi">22</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">35</span><span class="p">,</span><span class="mi">37</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">46</span><span class="p">]]).</span><span class="n">T</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">16</span><span class="p">]]).</span><span class="n">T</span>

<span class="c1">#Visualize data 
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="sh">'</span><span class="s">ro</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># append column ones to matrix A
</span><span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">int8</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span><span class="n">A</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># calculate coefficients to fit a straight line
</span><span class="n">A_dagger</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">inv</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="nf">transpose</span><span class="p">().</span><span class="nf">dot</span><span class="p">(</span><span class="n">A</span><span class="p">)).</span><span class="nf">dot</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="nf">transpose</span><span class="p">())</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">A_dagger</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="c1"># start and end point of the straight line
</span><span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">46</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">y0</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x0</span>

<span class="c1"># plot the straight line
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">y0</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">x coordinates </span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">y coordinates </span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>
<p>Using Scikit learn library</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>

<span class="c1"># create random data 
</span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">19</span><span class="p">,</span><span class="mi">23</span><span class="p">,</span><span class="mi">22</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">35</span><span class="p">,</span><span class="mi">37</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">46</span><span class="p">]]).</span><span class="n">T</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">16</span><span class="p">]]).</span><span class="n">T</span>

<span class="c1">#Use Scikit Learn
</span><span class="n">lr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="p">.</span><span class="nc">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Solution found by scikit learn: w =</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span> <span class="c1">#w0
</span><span class="nf">print</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span> <span class="c1">#w1
</span></code></pre></div></div>
<div class="imgcap">
	<img style="display: inline-block; width: 60%;" src="/public/post-assets/LinearRegression/plot1.png" width="500" align="center" />
	<div class="thecap">Code output</div>
</div>
<p>Fitting a prabole:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># create random data 
</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">19</span><span class="p">,</span><span class="mi">23</span><span class="p">,</span><span class="mi">22</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">35</span><span class="p">,</span><span class="mi">37</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">46</span><span class="p">,</span><span class="mi">42</span><span class="p">,</span><span class="mi">39</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">]]).</span><span class="n">T</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">19</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">22</span><span class="p">,</span><span class="mi">23</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">25</span><span class="p">]]).</span><span class="n">T</span>

<span class="c1">#Visualize data 
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="sh">'</span><span class="s">ro</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># append column ones to matrix A
</span><span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">int8</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span><span class="n">A</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1">## append x^2 to A
</span><span class="n">x_square</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">A</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">]).</span><span class="n">T</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">A</span><span class="p">,</span><span class="n">x_square</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># calculate coefficients to fit a straight line
</span><span class="n">A_dagger</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">inv</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="nf">transpose</span><span class="p">().</span><span class="nf">dot</span><span class="p">(</span><span class="n">A</span><span class="p">)).</span><span class="nf">dot</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="nf">transpose</span><span class="p">())</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">A_dagger</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="c1"># start and end point of the straight line
</span><span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">y0</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x0</span> <span class="o">+</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x0</span><span class="o">*</span><span class="n">x0</span>

<span class="c1"># plot the parabola
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">y0</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">x coordinates </span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">y coordinates </span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>
<div class="imgcap">
	<img style="display: inline-block; width: 60%;" src="/public/post-assets/LinearRegression/plot2.png" width="500" align="center" />
	<div class="thecap">Code output</div>
</div>
<p>This parabole seems to be underfitting. We need to make the regression equation more complex by adding features (add more dimension to \(C(A)\)).
<a name="6-further-topics-to-study"></a></p>
<h2 id="6-further-topics-to-study">6. Further topics to study</h2>
<ol>
  <li>Evaluation approach such as cross-validation (Determine which solution is the best)</li>
  <li>Normalization, data value could be in different scale and causing inconsistent.</li>
  <li>Regularization to avoid overfitting.</li>
</ol>

<p><a name="7-reference"></a></p>
<h2 id="7-reference">7. Reference</h2>
<ol>
  <li><a href="http://math.mit.edu/~gs/linearalgebra/">Introduction to Linear Algebra</a> book by Prof. Gilbert Strang.</li>
  <li>Andrew, Ng. , â€˜Machine learningâ€™, Standford University Online, lecture notes week 2, [online]: https://www.coursera.org/learn/machine-learning</li>
</ol>

</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/2018/07/26/linked-list/">
            Linked List, Stack, Queue
            <small>26 Jul 2018</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2018/07/10/cars-visualisation/">
            Interactive Visualisation
            <small>10 Jul 2018</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2018/04/09/NavigationTrainer/">
            Journey Preparation Tool Project
            <small>09 Apr 2018</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2018/01/25/SVD/">
            Singular Value Decomposition
            <small>25 Jan 2018</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2017/12/21/gradient-descent/">
            Gradient Descent
            <small>21 Dec 2017</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://dunglai-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if (!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>

  
</html>
